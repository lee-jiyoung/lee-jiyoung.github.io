<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143690801-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-143690801-1');
  </script>
  <title>Jiyoung Lee | Yonsei University</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="HTML5 website template">
  <meta name="keywords" content="global, template, html, sass, jquery">
  <meta name="author" content="Jiyoung Lee">
  <meta property="og:title" content="Jiyoung Lee | Yonsei University" />
  <meta property="og:image" content="assets/img/profile2.png"/>
  <link rel="stylesheet" href="assets/css/main.css">
  <link rel="stylesheet" href="assets/css/my.css">
  <link href="https://fonts.googleapis.com/css?family=Quicksand" rel="stylesheet" />
</head>
<body>

<!-- notification for small viewports and landscape oriented smartphones -->
<div class="device-notification">
  <a class="device-notification--logo" href="#">
    <!-- <img src="assets/img/logo.png" alt="Global"> -->
    <p>Jiyoung Lee | Yonsei University</p>
  </a>
  <p class="device-notification--message"></p>
</div>

<div class="perspective effect-rotate-left">
  <div class="container"><div class="outer-nav--return"></div>
    <div id="viewport" class="l-viewport">
      <div class="l-wrapper">
        <header class="header">
          <a class="header--logo" href="#0">
            <!-- <img src="assets/img/logo.png" alt="Global"> -->
            <p>Jiyoung Lee</p>
          </a>
          <button class="header--cta cta">Contact</button>
          <div class="header--nav-toggle">
            <span></span>
          </div>
        </header>
        <nav class="l-side-nav">
          <ul class="side-nav">
            <li class="is-active"><span>Home</span></li>
            <li><span>About</span></li>
            <li><span>Publication</span></li>
            <li><span>Project</span></li>
            <li><span>Media Coverages</span></li>
            <li><span>Contact</span></li>
          </ul>
        </nav>
        <ul class="l-main-content main-content">
          <li class="l-section section section--is-active">
            <div class="intro">
              <div class="intro--banner">
                      <h1 style="font-weight: 400;"><br />Jiyoung Lee<br/></h1>
                      <h2 style="font-weight: 400;">
                          Researcher<br/>
                          Ph.D. Candidate<br/>
                          Computer Vision & AI</h2>
                      <!-- <h3>Computer Vision</h3> -->
                      <a href="assets/file/JiyoungLee_CV.pdf" style="text-decoration:none; color:white;">
                      <button class="cta" style="">Curriculum Vitae
                        <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 150 118" style="enable-background:new 0 0 150 118;" xml:space="preserve">
                        <g transform="translate(0.000000,118.000000) scale(0.100000,-0.100000)">
                          <path d="M870,1167c-34-17-55-57-46-90c3-15,81-100,194-211l187-185l-565-1c-431,0-571-3-590-13c-55-28-64-94-18-137c21-20,33-20,597-20h575l-192-193C800,103,794,94,849,39c20-20,39-29,61-29c28,0,63,30,298,262c147,144,272,271,279,282c30,51,23,60-219,304C947,1180,926,1196,870,1167z"/>
                        </g>
                        </svg>
                        <span class="btn-background"></span>
                    </button>
                    </a>
                <img src="assets/img/profile2.png" style="width:464px; margin:auto;" alt="Welcome">

                <!-- <img src="assets/img/profile2.png" style="width:400px;" alt="Welcome"> -->
              </div>
              <div class="intro--options">
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Yonsei University
                      </span>
                      <br/>Ph.D. Candidate
                  </p>
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Researcher
                      </span>
                      <br/>Computer Vision & AI
                  </p>
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Developer
                      </span>
                      <br/>A.I. &amp; Web &amp; Program
                  </p>
              </div>
              <div>
                  <h2 style="font-weight: 400;">
                      <br/>News<br/>
                 </h2>
                 <p>
                     <span style="font-size:16px;">
			     			05/2021, Our paper on meta-learning was accepted to ICIP 2021<br/>
					 	03/2021, Our two papers were accepted to CVPR 2021<br/>
					 	07/2020, Our paper on video summarization was accepted to ECCV 2020<br/>
					 	05/2020, Our paper on facial expression recognition was accepted to
						<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE TIP</a><br/>
                         <a href="https://techxplore.com/news/2019-08-deep-technique-context-aware-emotion-recognition.html">
                             08/2019, Our paper related to emotion recognition was posted at TechXplore<br/>
                         </a>
						 01/2020, I will join Human Understanding and Empathy Group, Microsoft, Redmond, United States in this year for research internship.<br/>
                         08/2019, Our team won the 3rd place in 'video summarization with action and scene recognition in untrimmed videos' task of CoVieW'19 (ICCV Workshop)<br/>
                         07/2019, Our paper was accepted to ICCV 2019<br/>
                         05/2019, Our paper was accepted to ICIP 2019
                     </span>
                 </p>
              </div>
            </div>

          </li>

          <li class="l-section section">
            <div class="about">
              <div class="about--banner">
                <h2 style="font-weight: 400;">
                    I'm Jiyoung Lee,<br />
                </h2>
                <h3 style="font-weight: 400;">
                    Ph.D. Candidate at the School of Electrical & Electronic Engineering,
                    <br/>
                    Yonsei University, Seoul, Korea.
                    <br/>
                    My work explores topics in computer vision and deep learning.
                    <br/>
                    For more check out my CV and contact me by email.
                </h3>
                <a href="assets/file/JiyoungLee_CV.pdf" style="font-size:16px;">CV
                  <span>
                    <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 150 118" style="enable-background:new 0 0 150 118;" xml:space="preserve">
                    <g transform="translate(0.000000,118.000000) scale(0.100000,-0.100000)">
                      <path d="M870,1167c-34-17-55-57-46-90c3-15,81-100,194-211l187-185l-565-1c-431,0-571-3-590-13c-55-28-64-94-18-137c21-20,33-20,597-20h575l-192-193C800,103,794,94,849,39c20-20,39-29,61-29c28,0,63,30,298,262c147,144,272,271,279,282c30,51,23,60-219,304C947,1180,926,1196,870,1167z"/>
                    </g>
                    </svg>
                  </span>
                </a>
                <!-- <img src="assets/img/about-visual.png" alt="About Us"> -->
              </div>
              <div class="intro--options">
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Programming
                      </span>
                      <br/>Python, C/C++, Java, Lua, MATLAB, Linux
                  </p>
              </div>
              <div class="intro--options">
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Deep Learning Library
                      </span>
                      <br/>PyTorch, Tensorflow, Torch, Caffe, MatConvNet
                  </p>
              </div>
              <div class="intro--options">
                  <p>
                      <span style="font-size:16px; font-weight:bold; text-transform:uppercase;">
                          Web
                      </span>
                      <br/>Django, Ruby on Rails, HTML5/CSS, Javascript
                  </p>
              </div>
              <!-- <div class="about--options">
                <a href="#0">
                  <h3>Winners</h3>
                </a>
                <a href="#0">
                  <h3>Philosophy</h3>
                </a>
                <a href="#0">
                  <h3>History</h3>
                </a>
              </div> -->
            </div>
          </li>
          <li class="l-section section">
              <div class="intro" >
                  <h2>Publication</h2>
                  <div class="" style="overflow:auto; height:80%;">
                    <h3 style="font:italic bold;">Journal</h3><hr/>
                    <p style="color:#999999;">
                          Jiyoung Lee, Seungryong Kim, Sunok Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                            Learning Discriminative Action Tubelets for Weakly-Supervised Action Detection
                              <a class="pdf-btn" href="/" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             Pattern Recognition,
                          </span>
                          (PR), (Under Review). May. 2021.
                    </p>
			  
		    <p style="color:#999999;">
                          Jungin Park, Jiyoung Lee, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                            Recursive Spatio-temporal Graph Relation Networks for Video Summarization
                              <a class="pdf-btn" href="/" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE Transactions on Neural Networks and Learning Systems,
                          </span>
                          (TNNLS), (Under Review). May. 2021.
                    </p>

                    <p style="color:#999999;">
                          Jiyoung Lee, Sunok Kim, Seungryong Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Multi-modal Recurrent Attention Networks for Facial Expression Recognition
                              <a class="pdf-btn" href="assets/publication/tip20_Jiyoung_Lee.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE Transaction on Image Processing,
                          </span>
                          (TIP), Mar. 2020.
                      </p>
		
		<br/>
		<h3>Conference</h3><hr/>

		    <p style="color:#999999;">
                         Jin Kim, Jiyoung Lee, Jungin Park, Dongbo Min and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                             Self-balanced Learning for Domain Generalization 
                              <a class="pdf-btn" href="/" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE International Conference on Image Processing
                          </span>
                          (ICIP), Sep. 2021.
                      </p>			  
			  
		    <p style="color:#999999;">
                         Jiyoung Lee*, Soo-Whan Chung*, Sunok Kim, Hong-Goo Kang and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                             Looking into Your Speech: Learning Cross-modal Affinity for Audio-visual Speech Separation 
                              <a class="pdf-btn" href="https://arxiv.org/abs/2104.02775" role="button">Paper</a>
                              <a class="pdf-btn" href="/" role="button">Project</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE/CVF Conference on Computer Vision and Pattern Recognition
                          </span>
                          (CVPR), Jun. 2021.
                      </p>

		    <p style="color:#999999;">
                         Jungin Park, Jiyoung Lee, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                             Bridge to Answer: Structure-aware Graph Interaction Network for Video Question Answering 
                              <a class="pdf-btn" href="https://arxiv.org/abs/2104.14085" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE/CVF Conference on Computer Vision and Pattern Recognition
                          </span>
                          (CVPR), Jun. 2021.
                      </p>

                    <p style="color:#999999;">
                        Jungin Park*, Jiyoung Lee*, Ig-Jae Kim, and Kwanghoon Sohn (* indicates equal contribution.)<br/>
                        <span style="font-size:16px; font-weight:bold; color: white;">
                            SumGraph: Video summarization via Recursive Graph Modeling
                            <a class="pdf-btn" href="https://arxiv.org/abs/2007.08809" role="button">Paper</a>
                        </span>
                        <br/>in
                        <span style="font-style:italic;">
                           European Conference on Computer Vision,
                        </span>
                        (ECCV), Aug. 2020.
                    </p>

			

                      <p style="color:#999999;">
                          Jungin Park, Jiyoung Lee, Sangryul Jeon, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Video Summarization by Learning Relationships between Action and Scene
                              <a class="pdf-btn" href="assets/publication/iccvw19_Jungin_Park.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE International Conference on Computer Vision Workshop
                          </span>
                          (ICCV Workshop), Oct. 2019.
                      </p>
                      <p style="color:#999999;">
                         Jiyoung Lee, Seungryong Kim, Sunok Kim, Jungin Park and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                             Context-Aware Emotion Recognition Networks
                              <a class="pdf-btn" href="assets/publication/iccv19_Jiyoung_Lee.pdf" role="button">Paper</a>
                              <a class="pdf-btn" href="https://caer-dataset.github.io/" role="button">Project</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             IEEE International Conference on Computer Vision
                          </span>
                          (ICCV), Oct. 2019.
                      </p>
                                            <p style="color:#999999;">
                          Jungin Park, Jiyoung Lee, Sangryul Jeon, Seungryong Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Graph Regularization Network With Semantic Affinity for Weakly-supervised Temporal Action Localization
                              <a class="pdf-btn" href="assets/publication/icip19_Jungin_Park.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             Proc. IEEE International Conference on Image Processing
                          </span>
                          (ICIP), Sep. 2019.
                      </p>
                      <p style="color:#999999;">
                          Jiyoung Lee, Sunok Kim, Seungryong Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Audio-Visual Attention Networks for Emotion Recognition
                              <a class="pdf-btn" href="assets/publication/acmmm18_Jiyoung_Lee.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             Proc. ACM Multimedia Workshop- Workshop on Audio-Visual Scene
Understanding for Immersive Multimedia
                          </span>
                          (MMW), Oct. 2018.
                      </p>
                      <p style="color:#999999;">
                          Jungin Park, Sangryul Jeon, Seungryong Kim, Jiyoung Lee, Sunok Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Learning to Detect, Associate, and Recognize Human Actions and Surrounding Scenes in Untrimmed Videos
                              <a class="pdf-btn" href="assets/publication/acmmmw18_Jungin_Park.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             Proc. ACM Multimedia Workshop- The 1st Workshop and Challenge on
Comprehensive Vidoe Understanding in the Wild
                          </span>
                          (MMW), Oct. 2018.
                      </p>
                      <p style="color:#999999;">
                          Jiyoung Lee, Sunok Kim, Seungryong Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Spatiotemporal Attention Based Deep Neural Networks for Emotion Recognition
                              <a class="pdf-btn" href="assets/publication/icassp18_Jiyoung_Lee.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                             Proc. IEEE International Conference on Acoustics, Speech and Signal Processing
                          </span>
                          (ICASSP), Apr. 2018.
                      </p>
                      <p style="color:#999999;">
                          Jiyoung Lee, Hyungjoo Jung, Youngjung Kim, and Kwanghoon Sohn<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                              Automatic 2D-to-3D Conversion using Multi-scale Deep Neural Network
                              <a class="pdf-btn" href="assets/publication/icip17_Jiyoung_Lee.pdf" role="button">Paper</a>
                          </span>
                          <br/>in
                          <span style="font-style:italic;">
                              Proc. IEEE International Conference on Image Processing
                          </span>
                          (ICIP), Sep. 2017.
                      </p>
                  </div>
              </div>
          </li>

          <li class="l-section section">
            <div class="intro">

              <div class="projects-div slideshow-container">
                  <h2>Project</h2>
                  <div class="projects mySlides fade">
                      <div class="images-right">
                          <img src="assets/img/csz.png" />
                      </div>
                      <div class="projects-contents">
                          <h3>
                              Research on Fundamental Technology <br />
                              for Deep Learning-Based Semantic State Understanding
                          </h3>
                          <p class="fund">
                              Funded by National Research Foundation Ministry of Science<br />
                              2017 - Present<br />
                          </p>
                          <p>
                              Developed an algorithm for understanding untrimmed videos
                          </p>
                      </div>
                </div>
                <div class="projects mySlides fade">
                    <div class="images-left">
                        <img src="assets/img/KR-UK.png" />
                    </div>
                    <div class="projects-contents-right">
                        <h3>
                          Intelligent Virtual Reality: <br />
                          Deep Audio-Visual Representation Learning <br />
                          for Multimedia Perception and Reproduction
                        </h3>
                        <p class="fund">
                          Funded by Institute of Information & Communication Technology<br />
                          2017 - Present<br />
                        </p>
                        <p>
                          Developed deep network using audio-visual data
                        </p>
                    </div>
                </div>
                <div class="projects mySlides fade">
                    <div class="images-right">
                        <img src="assets/img/emotion.png" />
                    </div>
                    <div class="projects-contents">
                        <h3>
                          Emotional Intelligence Technology to <br />
                          Infer Human Emotion and Carry on Dialogue Accordingly
                        </h3>
                        <p class="fund">
                          Funded by Institute of Information \& Communication Technology<br />
                          2017 - 2018 <br />
                        </p>
                        <p>
                          Developed an algorithm for inferring human emotion from multi-spectral images
                        </p>
                    </div>
                </div>
                <div class="projects mySlides fade">
                    <div class="images-left">
                        <img src="assets/img/digital_contents.png" />
                    </div>
                    <div class="projects-contents-right">
                        <h3>
                            High Quality 2D-to-Multiview Contents Generation <br />
                            from Large-Scale RGB+D Database
                        </h3>
                        <p class="fund">
                            Funded by Institute of Information & Communication Technology<br />
                            2016 - 2017<br />
                        </p>
                        <p>
                            Developed deep network for inferring high-quality depth from a single 2-D image
                        </p>
                    </div>
                </div>


                <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
                <a class="next" onclick="plusSlides(1)">&#10095;</a>
                <div style="text-align:center">

                    <span class="dot" onclick="currentSlide(1)"></span>
                    <span class="dot" onclick="currentSlide(2)"></span>
                    <span class="dot" onclick="currentSlide(3)"></span>
                    <span class="dot" onclick="currentSlide(4)"></span>
                </div>

            </div>

            </div>
          </li>

          <li class="l-section section">
              <div class="intro">
                  <h2>Media Coverages</h2>
                  <div class="">
                      <p style="color:#999999;">
                         TechXplore, August 28, 2019<br/>
                          <span style="font-size:16px; font-weight:bold; color: white;">
                             A deep learning technique for context-aware emotion recognition
                              <a class="pdf-btn" href="https://techxplore.com/news/2019-08-deep-technique-context-aware-emotion-recognition.html" role="button">View</a>
                          </span>
                          <br/>
                      </p>
                  </div>
              </div>
          </li>
          <li class="l-section section">
            <div class="contact">
              <div class="contact--lockup">
                <div class="modal">
                  <div class="modal--information">
                    <p>C129, The 3rd Engineering Building, Yonsei University,
                        50 Yonsei-ro, Seodaemun-Gu, Seoul, Korea</p>
                    <a href="mailto:easy00@yonsei.ac.kr">easy00@yonsei.ac.kr</a>
                    <a href="tel:+82221232879">+82-2-2123-2879</a>
                  </div>
                  <ul class="modal--options">
                    <li><a href="mailto:easy00@yonsei.ac.kr">Contact Us</a></li>
                  </ul>
                </div>
              </div>
            </div>
          </li>
          <!-- <li class="l-section section">
            <div class="hire">
              <h2>Interest</h2>
              checkout formspree.io for easy form setup
              <form class="work-request" method="post" action="assets/php/send_form_email.php" >
                <div class="work-request--options">
                  <span class="options-a">
                    <input id="opt-1" type="checkbox" value="app design">
                    <label for="opt-1">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Computer Vision
                    </label>
                    <input id="opt-2" type="checkbox" value="graphic design">
                    <label for="opt-2">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Image Processing
                    </label>
                    <input id="opt-3" type="checkbox" value="motion design">
                    <label for="opt-3">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Sequential Learning
                    </label>
                  </span>
                  <span class="options-b">
                    <input id="opt-4" type="checkbox" value="ux design">
                    <label for="opt-4">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Emotion Recognition
                    </label>
                    <input id="opt-5" type="checkbox" value="webdesign">
                    <label for="opt-5">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Deep Learning
                    </label>
                    <input id="opt-6" type="checkbox" value="marketing">
                    <label for="opt-6">
                      <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                      viewBox="0 0 150 111" style="enable-background:new 0 0 150 111;" xml:space="preserve">
                      <g transform="translate(0.000000,111.000000) scale(0.100000,-0.100000)">
                        <path d="M950,705L555,310L360,505C253,612,160,700,155,700c-6,0-44-34-85-75l-75-75l278-278L550-5l475,475c261,261,475,480,475,485c0,13-132,145-145,145C1349,1100,1167,922,950,705z"/>
                      </g>
                      </svg>
                      Audio-Visual
                    </label>
                  </span>
                </div>
                <div class="work-request--information">
                  <div class="information-name">
                    <input id="name" type="text" spellcheck="false">
                    <label for="name">Name</label>
                  </div>
                  <div class="information-email">
                    <input id="email" type="email" spellcheck="false">
                    <label for="email">Email</label>
                  </div>
                </div>
                <a class="send-emaion-btn" href="mailto:easy00@yonsei.ac.kr">Send</a>
            </div>
          </li> -->
        </ul>
      </div>
    </div>
  </div>
  <ul class="outer-nav">
    <li class="is-active">Home</li>
    <li>About</li>
    <li>Publication</li>
    <li>Project</li>
    <li>Media Coverages</li>
    <li>Contact</li>
  </ul>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="assets/js/vendor/jquery-2.2.4.min.js"><\/script>')</script>
<script src="assets/js/functions-min.js"></script>
<script>
    var slideIndex = 1;
    showSlides(slideIndex);

    function plusSlides(n) {
      showSlides(slideIndex += n);
    }

    function currentSlide(n) {
      showSlides(slideIndex = n);
    }

    function showSlides(n) {
      var i;
      var slides = document.getElementsByClassName("mySlides");
      var dots = document.getElementsByClassName("dot");
      if (n > slides.length) {slideIndex = 1}
      if (n < 1) {slideIndex = slides.length}
      for (i = 0; i < slides.length; i++) {
          slides[i].style.display = "none";
      }
      for (i = 0; i < dots.length; i++) {
          dots[i].className = dots[i].className.replace(" active", "");
      }
      slides[slideIndex-1].style.display = "block";
      dots[slideIndex-1].className += " active";
    }
</script>

</body>
</html>
